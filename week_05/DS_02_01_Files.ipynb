{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Working with different file formats\n"]},{"cell_type":"markdown","metadata":{},"source":["In the real-world, people rarely get neat tabular data. Thus, it is mandatory for any data scientist (or data engineer) to be aware of different file formats, common challenges in handling them and the best, most efficient ways to handle this data in real life. We have reviewed some of this content in other modules.\n"]},{"cell_type":"markdown","metadata":{},"source":["#### File Format\n"]},{"cell_type":"markdown","metadata":{},"source":["A file format is a standard way in which information is encoded for storage in a file. First, the file format specifies whether the file is a binary or ASCII file. Second, it shows how the information is organized. For example, the comma-separated values (CSV) file format stores tabular data in plain text.\n","\n","To identify a file format, you can usually look at the file extension to get an idea. For example, a file saved with name “Data” in “CSV” format will appear as “Data.csv”. By noticing the “.csv” extension, we can clearly identify that it is a “CSV” file and the data is stored in a tabular format.\n"]},{"cell_type":"markdown","metadata":{},"source":["There are various formats for a dataset, .csv, .json, .xlsx etc. The dataset can be stored in different places, on your local machine or sometimes online."]},{"cell_type":"markdown","metadata":{},"source":["# Comma-separated values (CSV) file format\n"]},{"cell_type":"markdown","metadata":{},"source":["The **Comma-separated values** file format falls under a spreadsheet file format.\n","\n","In a spreadsheet file format, data is stored in cells. Each cell is organized in rows and columns. A column in the spreadsheet file can have different types. For example, a column can be of string type, a date type, or an integer type.\n","\n","Each line in CSV file represents an observation, or commonly called a record. Each record may contain one or more fields which are separated by a comma.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Reading data from CSV in Python\n"]},{"cell_type":"markdown","metadata":{},"source":["The **Pandas** Library is a useful tool that enables us to read various datasets into a Pandas data frame\n","\n","Let us look at how to read a CSV file in Pandas Library.\n","\n","We use **pandas.read_csv()** function to read the csv file. In the parentheses, we put the file path along with a quotation mark as an argument, so that pandas will read the file into a data frame from that address. The file path can be either a URL or your local file address.\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["url ='data/concrete_data.csv'\n","df = pd.read_csv(url,header=None)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Cement</td>\n","      <td>Blast Furnace Slag</td>\n","      <td>Fly Ash</td>\n","      <td>Water</td>\n","      <td>Superplasticizer</td>\n","      <td>Coarse Aggregate</td>\n","      <td>Fine Aggregate</td>\n","      <td>Age</td>\n","      <td>Strength</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>540.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>162.0</td>\n","      <td>2.5</td>\n","      <td>1040.0</td>\n","      <td>676.0</td>\n","      <td>28</td>\n","      <td>79.99</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>540.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>162.0</td>\n","      <td>2.5</td>\n","      <td>1055.0</td>\n","      <td>676.0</td>\n","      <td>28</td>\n","      <td>61.89</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>332.5</td>\n","      <td>142.5</td>\n","      <td>0.0</td>\n","      <td>228.0</td>\n","      <td>0.0</td>\n","      <td>932.0</td>\n","      <td>594.0</td>\n","      <td>270</td>\n","      <td>40.27</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>332.5</td>\n","      <td>142.5</td>\n","      <td>0.0</td>\n","      <td>228.0</td>\n","      <td>0.0</td>\n","      <td>932.0</td>\n","      <td>594.0</td>\n","      <td>365</td>\n","      <td>41.05</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1026</th>\n","      <td>276.4</td>\n","      <td>116.0</td>\n","      <td>90.3</td>\n","      <td>179.6</td>\n","      <td>8.9</td>\n","      <td>870.1</td>\n","      <td>768.3</td>\n","      <td>28</td>\n","      <td>44.28</td>\n","    </tr>\n","    <tr>\n","      <th>1027</th>\n","      <td>322.2</td>\n","      <td>0.0</td>\n","      <td>115.6</td>\n","      <td>196.0</td>\n","      <td>10.4</td>\n","      <td>817.9</td>\n","      <td>813.4</td>\n","      <td>28</td>\n","      <td>31.18</td>\n","    </tr>\n","    <tr>\n","      <th>1028</th>\n","      <td>148.5</td>\n","      <td>139.4</td>\n","      <td>108.6</td>\n","      <td>192.7</td>\n","      <td>6.1</td>\n","      <td>892.4</td>\n","      <td>780.0</td>\n","      <td>28</td>\n","      <td>23.70</td>\n","    </tr>\n","    <tr>\n","      <th>1029</th>\n","      <td>159.1</td>\n","      <td>186.7</td>\n","      <td>0.0</td>\n","      <td>175.6</td>\n","      <td>11.3</td>\n","      <td>989.6</td>\n","      <td>788.9</td>\n","      <td>28</td>\n","      <td>32.77</td>\n","    </tr>\n","    <tr>\n","      <th>1030</th>\n","      <td>260.9</td>\n","      <td>100.5</td>\n","      <td>78.3</td>\n","      <td>200.6</td>\n","      <td>8.6</td>\n","      <td>864.5</td>\n","      <td>761.5</td>\n","      <td>28</td>\n","      <td>32.40</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1031 rows × 9 columns</p>\n","</div>"],"text/plain":["           0                   1        2       3                 4  \\\n","0     Cement  Blast Furnace Slag  Fly Ash   Water  Superplasticizer   \n","1     540.0                 0.0      0.0   162.0               2.5    \n","2     540.0                 0.0      0.0   162.0               2.5    \n","3     332.5               142.5      0.0   228.0               0.0    \n","4     332.5               142.5      0.0   228.0               0.0    \n","...      ...                 ...      ...     ...               ...   \n","1026  276.4               116.0     90.3   179.6               8.9    \n","1027  322.2                 0.0    115.6   196.0              10.4    \n","1028  148.5               139.4    108.6   192.7               6.1    \n","1029  159.1               186.7      0.0   175.6              11.3    \n","1030  260.9               100.5     78.3   200.6               8.6    \n","\n","                     5               6     7         8  \n","0     Coarse Aggregate  Fine Aggregate   Age  Strength  \n","1              1040.0           676.0    28     79.99   \n","2              1055.0           676.0    28     61.89   \n","3               932.0           594.0   270     40.27   \n","4               932.0           594.0   365     41.05   \n","...                ...             ...   ...       ...  \n","1026            870.1           768.3    28     44.28   \n","1027            817.9           813.4    28     31.18   \n","1028            892.4           780.0    28     23.70   \n","1029            989.6           788.9    28     32.77   \n","1030            864.5           761.5    28     32.40   \n","\n","[1031 rows x 9 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{},"source":["# JSON file Format\n"]},{"cell_type":"markdown","metadata":{},"source":["**JSON (JavaScript Object Notation)** is a lightweight data-interchange format. It is easy for humans to read and write.\n","\n","JSON is built on two structures:\n","\n","1. A collection of name/value pairs. In various languages, this is realized as an object, record, struct, dictionary, hash table, keyed list, or associative array.\n","\n","2. An ordered list of values. In most languages, this is realized as an array, vector, list, or sequence.\n","\n","JSON is a language-independent data format. It was derived from JavaScript, but many modern programming languages include code to generate and parse JSON-format data. It is a very common data format with a diverse range of applications.\n"]},{"cell_type":"markdown","metadata":{},"source":["The text in JSON is done through quoted string which contains the values in key-value mappings within { }. It is similar to the dictionary in Python.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["Python supports JSON through a built-in package called **json**. To use this feature, we import the json package in Python script.\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import json"]},{"cell_type":"markdown","metadata":{},"source":["# Writing JSON to a File\n","\n","This is usually called **serialization**. It is the process of converting an object into a special format which is suitable for transmitting over the network or storing in file or database.\n","\n","To handle the data flow in a file, the JSON library in Python uses the **dump()** or **dumps()** function to convert the Python objects into their respective JSON object. This makes it easy to write data to files.\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import json\n","person = {\n","    'first_name' : 'Mark',\n","    'last_name' : 'abc',\n","    'age' : 27,\n","    'address': {\n","        \"streetAddress\": \"21 2nd Street\",\n","        \"city\": \"New York\",\n","        \"state\": \"NY\",\n","        \"postalCode\": \"10021-3100\"\n","    }\n","}"]},{"cell_type":"markdown","metadata":{},"source":["#### Serialization using dump() function\n","\n","**json.dump()** method can be used for writing to JSON file.\n","\n","Syntax: json.dump(dict, file_pointer)\n","\n","Parameters:\n","\n","1. **dictionary** – name of the dictionary which should be converted to JSON object.\n","2. **file pointer** – pointer of the file opened in write or append mode.\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["with open('data/person.json', 'w') as f:  # writing JSON object\n","    json.dump(person, f)"]},{"cell_type":"markdown","metadata":{},"source":["#### serialization using dumps() function\n","\n","**json.dumps()** that helps in converting a dictionary to a JSON object.\n","\n","It takes two parameters:\n","1. **dictionary** – name of the dictionary which should be converted to JSON object.\n","2. **indent** – defines the number of units for indentation\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Serializing json  \n","json_object = json.dumps(person, indent = 4) \n","  \n","# Writing to sample.json \n","with open(\"data/sample.json\", \"w\") as outfile: \n","    outfile.write(json_object) "]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","    \"first_name\": \"Mark\",\n","    \"last_name\": \"abc\",\n","    \"age\": 27,\n","    \"address\": {\n","        \"streetAddress\": \"21 2nd Street\",\n","        \"city\": \"New York\",\n","        \"state\": \"NY\",\n","        \"postalCode\": \"10021-3100\"\n","    }\n","}\n"]}],"source":["print(json_object)"]},{"cell_type":"markdown","metadata":{},"source":["Our Python objects are now serialized to the file. To deserialize it back to the Python object, we use the load() function.\n"]},{"cell_type":"markdown","metadata":{},"source":["# Reading JSON to a File\n"]},{"cell_type":"markdown","metadata":{},"source":["This process is usually called **Deserialization** - it is the reverse of serialization. It converts the special format returned by the serialization back into a usable object.\n","\n","### Using json.load()\n","\n","The JSON package has json.load() function that loads the json content from a json file into a dictionary.\n","\n","It takes one parameter:\n","\n","File pointer: A file pointer that points to a JSON file.\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'first_name': 'Mark', 'last_name': 'abc', 'age': 27, 'address': {'streetAddress': '21 2nd Street', 'city': 'New York', 'state': 'NY', 'postalCode': '10021-3100'}}\n","<class 'dict'>\n"]}],"source":["import json \n","  \n","# Opening JSON file \n","with open('data/sample.json', 'r') as openfile: \n","  \n","    # Reading from json file \n","    json_object = json.load(openfile) \n","  \n","print(json_object) \n","print(type(json_object)) "]},{"cell_type":"markdown","metadata":{},"source":["# XLSX file format\n"]},{"cell_type":"markdown","metadata":{},"source":["**XLSX** is a Microsoft Excel Open XML file format. It is another type of Spreadsheet file format.\n","\n","In XLSX data is organized under the cells and columns in a sheet.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Reading the data from XLSX file\n"]},{"cell_type":"markdown","metadata":{},"source":["Let’s load the data from XLSX file and define the sheet name. For loading the data you can use the Pandas library in python.\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["df = pd.read_excel(\"data/file_example_XLSX_10.xlsx\")"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>First Name</th>\n","      <th>Last Name</th>\n","      <th>Gender</th>\n","      <th>Country</th>\n","      <th>Age</th>\n","      <th>Date</th>\n","      <th>Id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Dulce</td>\n","      <td>Abril</td>\n","      <td>Female</td>\n","      <td>United States</td>\n","      <td>32</td>\n","      <td>15/10/2017</td>\n","      <td>1562</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Mara</td>\n","      <td>Hashimoto</td>\n","      <td>Female</td>\n","      <td>Great Britain</td>\n","      <td>25</td>\n","      <td>16/08/2016</td>\n","      <td>1582</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Philip</td>\n","      <td>Gent</td>\n","      <td>Male</td>\n","      <td>France</td>\n","      <td>36</td>\n","      <td>21/05/2015</td>\n","      <td>2587</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>Kathleen</td>\n","      <td>Hanner</td>\n","      <td>Female</td>\n","      <td>United States</td>\n","      <td>25</td>\n","      <td>15/10/2017</td>\n","      <td>3549</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Nereida</td>\n","      <td>Magwood</td>\n","      <td>Female</td>\n","      <td>United States</td>\n","      <td>58</td>\n","      <td>16/08/2016</td>\n","      <td>2468</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>Gaston</td>\n","      <td>Brumm</td>\n","      <td>Male</td>\n","      <td>United States</td>\n","      <td>24</td>\n","      <td>21/05/2015</td>\n","      <td>2554</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>Etta</td>\n","      <td>Hurn</td>\n","      <td>Female</td>\n","      <td>Great Britain</td>\n","      <td>56</td>\n","      <td>15/10/2017</td>\n","      <td>3598</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>Earlean</td>\n","      <td>Melgar</td>\n","      <td>Female</td>\n","      <td>United States</td>\n","      <td>27</td>\n","      <td>16/08/2016</td>\n","      <td>2456</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>Vincenza</td>\n","      <td>Weiland</td>\n","      <td>Female</td>\n","      <td>United States</td>\n","      <td>40</td>\n","      <td>21/05/2015</td>\n","      <td>6548</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0 First Name  Last Name  Gender        Country  Age        Date    Id\n","0  1      Dulce      Abril  Female  United States   32  15/10/2017  1562\n","1  2       Mara  Hashimoto  Female  Great Britain   25  16/08/2016  1582\n","2  3     Philip       Gent    Male         France   36  21/05/2015  2587\n","3  4   Kathleen     Hanner  Female  United States   25  15/10/2017  3549\n","4  5    Nereida    Magwood  Female  United States   58  16/08/2016  2468\n","5  6     Gaston      Brumm    Male  United States   24  21/05/2015  2554\n","6  7       Etta       Hurn  Female  Great Britain   56  15/10/2017  3598\n","7  8    Earlean     Melgar  Female  United States   27  16/08/2016  2456\n","8  9   Vincenza    Weiland  Female  United States   40  21/05/2015  6548"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{},"source":["# XML file format\n"]},{"cell_type":"markdown","metadata":{},"source":["**XML is also known as Extensible Markup Language**. As the name suggests, it is a markup language. It has certain rules for encoding data. XML file format is a human-readable and machine-readable file format.\n","\n","Pandas does not include any methods to read and write XML files. Here, we will take a look at how we can use other modules to read data from an XML file, and load it into a Pandas DataFrame.\n"]},{"cell_type":"markdown","metadata":{},"source":["### Writing with xml.etree.ElementTree\n"]},{"cell_type":"markdown","metadata":{},"source":["The **xml.etree.ElementTree** module comes built-in with Python. It provides functionality for parsing and creating XML documents. ElementTree represents the XML document as a tree. We can move across the document using nodes which are elements and sub-elements of the XML file.\n","\n","For more information please read the [xml.etree.ElementTree](https://docs.python.org/3/library/xml.etree.elementtree.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork1005-2022-01-01) documentation.\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["import xml.etree.ElementTree as ET\n","\n","# create the file structure\n","employee = ET.Element('employee')\n","details = ET.SubElement(employee, 'details')\n","first = ET.SubElement(details, 'firstname')\n","second = ET.SubElement(details, 'lastname')\n","third = ET.SubElement(details, 'age')\n","first.text = 'Shiv'\n","second.text = 'Mishra'\n","third.text = '23'\n","\n","# create a new XML file with the results\n","mydata1 = ET.ElementTree(employee)\n","# myfile = open(\"items2.xml\", \"wb\")\n","# myfile.write(mydata)\n","with open(\"data/new_sample.xml\", \"wb\") as files:\n","    mydata1.write(files)"]},{"cell_type":"markdown","metadata":{},"source":["### Reading with xml.etree.ElementTree\n"]},{"cell_type":"markdown","metadata":{},"source":["Let's have a look at a one way to read XML data and put it in a Pandas DataFrame. You can see the XML file in the Notepad of your local machine.\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["import pandas as pd \n","\n","import xml.etree.ElementTree as etree"]},{"cell_type":"markdown","metadata":{},"source":["You would need to firstly parse an XML file and create a list of columns for data frame, then extract useful information from the XML file and add to a pandas data frame.\n","\n","Here is a sample code that you can use.:\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["tree = etree.parse(\"data/Sample-employee.xml\")\n","\n","root = tree.getroot()\n","columns = [\"firstname\", \"lastname\", \"title\", \"division\", \"building\",\"room\"]\n","\n","datatframe = pd.DataFrame(columns = columns)\n","\n","for node in root: \n","\n","    firstname = node.find(\"firstname\").text\n","\n","    lastname = node.find(\"lastname\").text \n","\n","    title = node.find(\"title\").text \n","    \n","    division = node.find(\"division\").text \n","    \n","    building = node.find(\"building\").text\n","    \n","    room = node.find(\"room\").text\n","    \n","    datatframe = datatframe._append(pd.Series([firstname, lastname, title, division, building, room], index = columns), ignore_index = True)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>firstname</th>\n","      <th>lastname</th>\n","      <th>title</th>\n","      <th>division</th>\n","      <th>building</th>\n","      <th>room</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Shiv</td>\n","      <td>Mishra</td>\n","      <td>Engineer</td>\n","      <td>Computer</td>\n","      <td>301</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Yuh</td>\n","      <td>Datta</td>\n","      <td>developer</td>\n","      <td>Computer</td>\n","      <td>303</td>\n","      <td>02</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Rahil</td>\n","      <td>Khan</td>\n","      <td>Tester</td>\n","      <td>Computer</td>\n","      <td>304</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Deep</td>\n","      <td>Parekh</td>\n","      <td>Designer</td>\n","      <td>Computer</td>\n","      <td>305</td>\n","      <td>14</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  firstname lastname      title  division building room\n","0      Shiv   Mishra   Engineer  Computer      301   11\n","1       Yuh    Datta  developer  Computer      303   02\n","2     Rahil     Khan     Tester  Computer      304   10\n","3      Deep   Parekh   Designer  Computer      305   14"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["datatframe"]},{"cell_type":"markdown","metadata":{},"source":["### Reading xml  file using pandas.read_xml function\n","\n","We can also read the downloaded xml file using the read_xml function present in the pandas library which returns a Dataframe object.\n","\n","For more information read the <a href=\"https://pandas.pydata.org/pandas-docs/dev/reference/api/pandas.read_xml.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0101ENSkillsNetwork1005-2022-01-01#pandas-read-xml\">pandas.read_xml</a> documentation.\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# Herein xpath we mention the set of xml nodes to be considered for migrating  to the dataframe which in this case is details node under employees.\n","df=pd.read_xml(\"data/Sample-employee.xml\", xpath=\"/employees/details\") "]},{"cell_type":"markdown","metadata":{},"source":["### Save Data\n"]},{"cell_type":"markdown","metadata":{},"source":["Correspondingly, Pandas enables us to save the dataset to csv by using the **dataframe.to_csv()** method, you can add the file path and name along with quotation marks in the parentheses.\n","\n","For example, if you would save the dataframe df as **employee.csv** to your local machine, you may use the syntax below:\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["datatframe.to_csv(\"data/employee.csv\", index=False)"]},{"cell_type":"markdown","metadata":{},"source":[" We can also read and save other file formats, we can use similar functions to **`pd.read_csv()`** and **`df.to_csv()`** for other data formats. The functions are listed in the following table:\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Read/Save Other Data Formats</h2>\n","\n","| Data Formate  | Read           | Save             |\n","| ------------- |:--------------:| ----------------:|\n","| csv           | `pd.read_csv()`  |`df.to_csv()`     |\n","| json          | `pd.read_json()` |`df.to_json()`    |\n","| excel         | `pd.read_excel()`|`df.to_excel()`   |\n","| hdf           | `pd.read_hdf()`  |`df.to_hdf()`     |\n","| sql           | `pd.read_sql()`  |`df.to_sql()`     |\n","| ...           |   ...          |       ...        |\n"]},{"cell_type":"markdown","metadata":{},"source":["# Binary File Format\n","\n","\"Binary\" files are any files where the format isn't made up of readable characters. It contain formatting information that only certain applications or processors can understand. While humans can read text files, binary files must be run on the appropriate software or processor before humans can read them.\n","\n","Binary files can range from image files like JPEGs or GIFs, audio files like MP3s or binary document formats like Word or PDF.\n","\n","Let's see how to read an **Image** file.\n","\n","## Reading the Image file\n","\n","Python supports very powerful tools when it comes to image processing. Let’s see how to process the images using the **PIL** library.\n","\n","PIL is the Python Imaging Library which provides the python interpreter with image editing capabilities.\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["('img/dog.jpg', <http.client.HTTPMessage at 0x17118ec0d90>)"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# importing PIL \n","from PIL import Image \n","\n","import urllib.request\n","# Downloading dataset\n","urllib.request.urlretrieve(\"https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/dog-puppy-on-garden-royalty-free-image-1586966191.jpg\", \"img/dog.jpg\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Read image \n","img = Image.open('img/dog.jpg') \n","  \n","# Output Images \n","display(img)"]}],"metadata":{"kernelspec":{"display_name":".my_env_04","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":4}
