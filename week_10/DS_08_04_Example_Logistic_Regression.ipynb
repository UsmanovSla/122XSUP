{"cells":[{"cell_type":"markdown","metadata":{"button":false,"new_sheet":false,"run_control":{"read_only":false}},"source":["# Logistic Regression with Python"]},{"cell_type":"markdown","metadata":{},"source":["# Predicting sentiment from product reviews\n","\n","\n","In this notebook we will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative.\n","\n","* Use Pandas to do some feature engineering.\n","* Train a logistic regression model to predict the sentiment of product reviews.\n","* Inspect the weights (coefficients) of a trained logistic regression model.\n","* Make a prediction (both class and probability) of sentiment for a new product review.\n","* Given the logistic regression weights, predictors and ground truth labels, write a function to compute the **accuracy** of the model.\n","* Inspect the coefficients of the logistic regression model and interpret their meanings.\n","* Compare multiple logistic regression models.\n","\n","Let's get started!"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Libraries Import\n","import string\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_extraction.text import CountVectorizer"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>review</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Planetwise Flannel Wipes</td>\n","      <td>These flannel wipes are OK, but in my opinion ...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Planetwise Wipe Pouch</td>\n","      <td>it came early and was not disappointed. i love...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Annas Dream Full Quilt with 2 Shams</td>\n","      <td>Very soft and comfortable and warmer than it l...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n","      <td>This is a product well worth the purchase.  I ...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n","      <td>All of my kids have cried non-stop when I trie...</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                name  \\\n","0                           Planetwise Flannel Wipes   \n","1                              Planetwise Wipe Pouch   \n","2                Annas Dream Full Quilt with 2 Shams   \n","3  Stop Pacifier Sucking without tears with Thumb...   \n","4  Stop Pacifier Sucking without tears with Thumb...   \n","\n","                                              review  rating  \n","0  These flannel wipes are OK, but in my opinion ...       3  \n","1  it came early and was not disappointed. i love...       5  \n","2  Very soft and comfortable and warmer than it l...       5  \n","3  This is a product well worth the purchase.  I ...       5  \n","4  All of my kids have cried non-stop when I trie...       5  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# read dataframe\n","dataframe = pd.read_csv(\"data/amazon_baby.csv\")\n","dataframe.head()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 183531 entries, 0 to 183530\n","Data columns (total 3 columns):\n"," #   Column  Non-Null Count   Dtype \n","---  ------  --------------   ----- \n"," 0   name    183213 non-null  object\n"," 1   review  182702 non-null  object\n"," 2   rating  183531 non-null  int64 \n","dtypes: int64(1), object(2)\n","memory usage: 4.2+ MB\n"]}],"source":["dataframe.info()\n","# contains null values for name, reviews"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# replace null values with empty string\n","dataframe = dataframe.fillna({'review': ''})"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>review_without_punctuation</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Planetwise Flannel Wipes</td>\n","      <td>These flannel wipes are OK but in my opinion n...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Planetwise Wipe Pouch</td>\n","      <td>it came early and was not disappointed i love ...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Annas Dream Full Quilt with 2 Shams</td>\n","      <td>Very soft and comfortable and warmer than it l...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n","      <td>This is a product well worth the purchase  I h...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n","      <td>All of my kids have cried nonstop when I tried...</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                name  \\\n","0                           Planetwise Flannel Wipes   \n","1                              Planetwise Wipe Pouch   \n","2                Annas Dream Full Quilt with 2 Shams   \n","3  Stop Pacifier Sucking without tears with Thumb...   \n","4  Stop Pacifier Sucking without tears with Thumb...   \n","\n","                          review_without_punctuation  rating  \n","0  These flannel wipes are OK but in my opinion n...       3  \n","1  it came early and was not disappointed i love ...       5  \n","2  Very soft and comfortable and warmer than it l...       5  \n","3  This is a product well worth the purchase  I h...       5  \n","4  All of my kids have cried nonstop when I tried...       5  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["#remove punctuations\n","def remove_punctuation(text):\n","    translator = str.maketrans('', '', string.punctuation)\n","    return text.translate(translator) \n","\n","dataframe[\"review_without_punctuation\"] = dataframe['review'].apply(lambda x : remove_punctuation(x))\n","dataframe = dataframe[[\"name\", \"review_without_punctuation\", \"rating\"]]\n","dataframe.head()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>review_without_punctuation</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Planetwise Wipe Pouch</td>\n","      <td>it came early and was not disappointed i love ...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Annas Dream Full Quilt with 2 Shams</td>\n","      <td>Very soft and comfortable and warmer than it l...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n","      <td>This is a product well worth the purchase  I h...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n","      <td>All of my kids have cried nonstop when I tried...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n","      <td>When the Binky Fairy came to our house we didn...</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                name  \\\n","0                              Planetwise Wipe Pouch   \n","1                Annas Dream Full Quilt with 2 Shams   \n","2  Stop Pacifier Sucking without tears with Thumb...   \n","3  Stop Pacifier Sucking without tears with Thumb...   \n","4  Stop Pacifier Sucking without tears with Thumb...   \n","\n","                          review_without_punctuation  rating  \n","0  it came early and was not disappointed i love ...       5  \n","1  Very soft and comfortable and warmer than it l...       5  \n","2  This is a product well worth the purchase  I h...       5  \n","3  All of my kids have cried nonstop when I tried...       5  \n","4  When the Binky Fairy came to our house we didn...       5  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# ignore all reviews with rating = 3, since they tend to have a neutral sentiment\n","dataframe = dataframe[dataframe[\"rating\"] != 3].reset_index(drop=True)\n","dataframe.head()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>review_without_punctuation</th>\n","      <th>rating</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Planetwise Wipe Pouch</td>\n","      <td>it came early and was not disappointed i love ...</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Annas Dream Full Quilt with 2 Shams</td>\n","      <td>Very soft and comfortable and warmer than it l...</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n","      <td>This is a product well worth the purchase  I h...</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n","      <td>All of my kids have cried nonstop when I tried...</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n","      <td>When the Binky Fairy came to our house we didn...</td>\n","      <td>5</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                name  \\\n","0                              Planetwise Wipe Pouch   \n","1                Annas Dream Full Quilt with 2 Shams   \n","2  Stop Pacifier Sucking without tears with Thumb...   \n","3  Stop Pacifier Sucking without tears with Thumb...   \n","4  Stop Pacifier Sucking without tears with Thumb...   \n","\n","                          review_without_punctuation  rating  sentiment  \n","0  it came early and was not disappointed i love ...       5          1  \n","1  Very soft and comfortable and warmer than it l...       5          1  \n","2  This is a product well worth the purchase  I h...       5          1  \n","3  All of my kids have cried nonstop when I tried...       5          1  \n","4  When the Binky Fairy came to our house we didn...       5          1  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# reviews with a rating of 4 or higher to be positive reviews, while the ones with rating of 2 \n","# or lower are negative. For the sentiment column, we use +1 for the positive class label and -1 \n","# for the negative class label\n","dataframe['sentiment'] = dataframe['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n","dataframe.head()"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>review_without_punctuation</th>\n","      <th>rating</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>166456</td>\n","      <td>166752</td>\n","      <td>166752.000000</td>\n","      <td>166752.000000</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>30729</td>\n","      <td>165873</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>Vulli Sophie the Giraffe Teether</td>\n","      <td></td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>723</td>\n","      <td>778</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>4.233191</td>\n","      <td>0.682247</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.295527</td>\n","      <td>0.731124</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.000000</td>\n","      <td>-1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>4.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>5.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                    name review_without_punctuation  \\\n","count                             166456                     166752   \n","unique                             30729                     165873   \n","top     Vulli Sophie the Giraffe Teether                              \n","freq                                 723                        778   \n","mean                                 NaN                        NaN   \n","std                                  NaN                        NaN   \n","min                                  NaN                        NaN   \n","25%                                  NaN                        NaN   \n","50%                                  NaN                        NaN   \n","75%                                  NaN                        NaN   \n","max                                  NaN                        NaN   \n","\n","               rating      sentiment  \n","count   166752.000000  166752.000000  \n","unique            NaN            NaN  \n","top               NaN            NaN  \n","freq              NaN            NaN  \n","mean         4.233191       0.682247  \n","std          1.295527       0.731124  \n","min          1.000000      -1.000000  \n","25%          4.000000       1.000000  \n","50%          5.000000       1.000000  \n","75%          5.000000       1.000000  \n","max          5.000000       1.000000  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["dataframe.describe(include = 'all')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["13_353_959\n"]}],"source":["dict_review = dataframe['review_without_punctuation'].to_dict()\n","print(f'{sum(len(review.split()) for review in list(dict_review.values())):_}')\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["165148\n"]}],"source":["from collections import Counter\n","words = Counter()\n","for review in list(dict_review.values()):\n","    words.update(review.split())\n","\n","words\n","print(len(words))\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>74</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>76</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>93</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>166747</th>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>166748</th>\n","      <td>64</td>\n","    </tr>\n","    <tr>\n","      <th>166749</th>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>166750</th>\n","      <td>170</td>\n","    </tr>\n","    <tr>\n","      <th>166751</th>\n","      <td>36</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>166752 rows × 1 columns</p>\n","</div>"],"text/plain":["        words\n","0          30\n","1          23\n","2          74\n","3          76\n","4          93\n","...       ...\n","166747     27\n","166748     64\n","166749     17\n","166750    170\n","166751     36\n","\n","[166752 rows x 1 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.DataFrame()\n","df['words'] = dataframe['review_without_punctuation'].str.split().str.len()\n","df"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["13353959"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df['words'].sum()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Train set: (133401, 3) (133401,)\n","Test set: (33351, 3) (33351,)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(dataframe[[\"name\",\"review_without_punctuation\",\"rating\"]], dataframe['sentiment'], test_size=0.2, random_state=1)\n","\n","print ('Train set:', X_train.shape,  y_train.shape)\n","print ('Test set:', X_test.shape,  y_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["<img src='img/Count-Vectorization.jpg' width=600px>"]},{"cell_type":"markdown","metadata":{},"source":["https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Build the word count vector for each review_without_punctuations\n","vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n","train_matrix = vectorizer.fit_transform(X_train['review_without_punctuation'])\n","test_matrix = vectorizer.transform(X_test['review_without_punctuation'])"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\usman\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n","  warnings.warn(\n"]},{"data":{"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(n_jobs=1, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=1, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"],"text/plain":["LogisticRegression(n_jobs=1, solver='liblinear')"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# Logistic model fit\n","sentiment_model = LogisticRegression(solver='liblinear', n_jobs=1)\n","sentiment_model.fit(train_matrix, y_train)"]},{"cell_type":"markdown","metadata":{},"source":["`LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=1,\n","          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n","          verbose=0, warm_start=False)`"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["121505"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["len(sentiment_model.coef_[0])"]},{"cell_type":"markdown","metadata":{},"source":["How many weights are greater than or equal to 0?"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["85930"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["np.sum(sentiment_model.coef_ >= 0)"]},{"cell_type":"markdown","metadata":{},"source":["Predict first five samples of X_test set:"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>review_without_punctuation</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>162318</th>\n","      <td>15 Plastic Alligator Grip Suspender Pacifier B...</td>\n","      <td>These clips are just what I was looking for  M...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>144241</th>\n","      <td>green sprouts 2 Count Cool Hand Teether, Green...</td>\n","      <td>This was a great buy the baby really loves che...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>10916</th>\n","      <td>Kidkusion Kid Safe Banister Guard</td>\n","      <td>Its a little amusing that this is marketed as ...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>50027</th>\n","      <td>Mommy's Helper Car Seat Sun Shade</td>\n","      <td>I live an area of the US where we get summers ...</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>40241</th>\n","      <td>Gerber Graduates BPA Free 4 Pack Bunch-A-Bowls...</td>\n","      <td>I ordered these to give to my daughter  she lo...</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                     name  \\\n","162318  15 Plastic Alligator Grip Suspender Pacifier B...   \n","144241  green sprouts 2 Count Cool Hand Teether, Green...   \n","10916                   Kidkusion Kid Safe Banister Guard   \n","50027                   Mommy's Helper Car Seat Sun Shade   \n","40241   Gerber Graduates BPA Free 4 Pack Bunch-A-Bowls...   \n","\n","                               review_without_punctuation  rating  \n","162318  These clips are just what I was looking for  M...       5  \n","144241  This was a great buy the baby really loves che...       5  \n","10916   Its a little amusing that this is marketed as ...       5  \n","50027   I live an area of the US where we get summers ...       5  \n","40241   I ordered these to give to my daughter  she lo...       5  "]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["X_test.head()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[-1  1]\n","[[3.10885504e-03 9.96891145e-01]\n"," [2.10430733e-03 9.97895693e-01]\n"," [5.63125868e-03 9.94368741e-01]\n"," [6.13089739e-05 9.99938691e-01]\n"," [4.82599390e-02 9.51740061e-01]]\n"]},{"data":{"text/plain":["{144241: 'This was a great buy the baby really loves chewing on these  especially after putting them in the refrigerator  We love it',\n"," 10916: 'Its a little amusing that this is marketed as an actual product the 34Banister Guard34 when in reality it is just a roll of plastic and some zip ties But it does work in guarding the banister so I guess Im OK with itThis kit also includes a hole punch for installation When punching holes in the plastic for the zip ties my recommendation is to toss that hole punch in with your artsandcrafts supplies and go grab an ice pick from the kitchen The ice pick worked great in creating holes that are the correct size for the zip ties The hole punch isnt quite strong enough to be effectiveOnce the plastic is installed it looks finevery transparent and if you can get it flat you can minimize any reflections Overall its a nice unobtrusive way to keep the kiddos away from those banister gaps',\n"," 50027: 'I live an area of the US where we get summers up to 120 degrees F  Placing little ones in their car seat in a 130140 degree car interior is always traumatic for everyone  Even though we have to crank the AC before we even place the kids in the car this cover helps keep all the metal bits from burning your munchkin itll still be warm but it wont burn  I recommend this product for any parent that lives with extreme summers',\n"," 40241: 'I ordered these to give to my daughter  she loves them and was especially happy to see that the bowls came with covers and more importantly that they are BPA Free  My grandson loves to feed himself and these are the perfect size for him',\n"," 125729: 'These were much softer than I thought I have Circo and carter wash clothes and these were just as soft if not softer Great for daily use'}"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["sample_test_data = X_test.iloc[1:6]\n","sample_test_matrix = vectorizer.transform(sample_test_data['review_without_punctuation'])\n","print(sentiment_model.classes_)\n","print(sentiment_model.predict_proba(sample_test_matrix))\n","sample_test_data['review_without_punctuation'].to_dict()\n"]},{"cell_type":"markdown","metadata":{},"source":["Which of the following products are represented in the 20 most positive reviews?"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["['Twist Breastfeeding Gift Set']"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["X_test[\"postive_review_probability\"] = [x[1] for x in np.asarray(sentiment_model.predict_proba(test_matrix))]\n","top_20 = list(X_test.sort_values(\"postive_review_probability\", ascending=False)[:20][\"name\"])\n","options_list = [\"Snuza Portable Baby Movement Monitor\",\n","                \"MamaDoo Kids Foldable Play Yard Mattress Topper, Blue\",\n","                \"Britax Decathlon Convertible Car Seat, Tiffany\",\n","                \"Safety 1st Exchangeable Tip 3 in 1 Thermometer\",\n","                \"Twist Breastfeeding Gift Set\"\n","                ]\n","[x for x in options_list if x in top_20]"]},{"cell_type":"markdown","metadata":{},"source":["Which of the following products are represented in the 20 most negative reviews?"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["['Belkin WeMo Wi-Fi Baby Monitor for Apple iPhone, iPad, and iPod Touch (Firmware Update)']"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["X_test[\"postive_review_probability\"] = [x[0] for x in np.asarray(sentiment_model.predict_proba(test_matrix))]\n","top_20 = list(X_test.sort_values(\"postive_review_probability\",ascending=False)[:20][\"name\"])\n","options_list = [\"The First Years True Choice P400 Premium Digital Monitor, 2 Parent Unit\",\n","                \"JP Lizzy Chocolate Ice Classic Tote Set\",\n","                \"Belkin WeMo Wi-Fi Baby Monitor for Apple iPhone, iPad, and iPod Touch (Firmware Update)\",\n","                \"Peg-Perego Tatamia High Chair, White Latte\",\n","                \"Safety 1st High-Def Digital Monitor\"\n","                ]\n","[x for x in options_list if x in top_20]"]},{"cell_type":"markdown","metadata":{},"source":["What is the accuracy of the sentiment_model on the test_data?"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["0.93"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["def get_classification_accuracy(model, data, true_labels):\n","    pred_y = model.predict(data)\n","    correct = np.sum(pred_y==true_labels)\n","    accuracy = round(correct / len(true_labels), 2)\n","    return accuracy\n","\n","get_classification_accuracy(sentiment_model, test_matrix, y_test)"]},{"cell_type":"markdown","metadata":{},"source":["### Simple model (20 words)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(n_jobs=1, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(n_jobs=1, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"],"text/plain":["LogisticRegression(n_jobs=1, solver='liblinear')"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n","      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n","      'work', 'product', 'money', 'would', 'return']\n","\n","\n","vectorizer_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 significant words\n","train_matrix_sub = vectorizer_word_subset.fit_transform(X_train['review_without_punctuation'])\n","test_matrix_sub = vectorizer_word_subset.transform(X_test['review_without_punctuation'])\n","# Logistic model fit\n","simple_model = LogisticRegression(solver='liblinear',n_jobs=1)\n","simple_model.fit(train_matrix_sub, y_train)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/plain":["10"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["simple_model_coefficient = pd.DataFrame({'word':significant_words, 'simple_model_coefficient':simple_model.coef_.flatten()}).sort_values(['simple_model_coefficient'], ascending=False).reset_index(drop=True)\n","len(simple_model_coefficient[simple_model_coefficient[\"simple_model_coefficient\"] > 0])"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>simple_model_coefficient</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>loves</td>\n","      <td>1.730101</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>perfect</td>\n","      <td>1.520583</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>love</td>\n","      <td>1.358388</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>easy</td>\n","      <td>1.172422</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>great</td>\n","      <td>0.953138</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>well</td>\n","      <td>0.516279</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>little</td>\n","      <td>0.486670</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>able</td>\n","      <td>0.208226</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>old</td>\n","      <td>0.092202</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>car</td>\n","      <td>0.062287</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>less</td>\n","      <td>-0.157199</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>product</td>\n","      <td>-0.311008</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>would</td>\n","      <td>-0.328955</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>even</td>\n","      <td>-0.536863</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>work</td>\n","      <td>-0.652401</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>money</td>\n","      <td>-0.901153</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>broke</td>\n","      <td>-1.711417</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>return</td>\n","      <td>-2.066739</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>waste</td>\n","      <td>-2.082077</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>disappointed</td>\n","      <td>-2.318348</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            word  simple_model_coefficient\n","0          loves                  1.730101\n","1        perfect                  1.520583\n","2           love                  1.358388\n","3           easy                  1.172422\n","4          great                  0.953138\n","5           well                  0.516279\n","6         little                  0.486670\n","7           able                  0.208226\n","8            old                  0.092202\n","9            car                  0.062287\n","10          less                 -0.157199\n","11       product                 -0.311008\n","12         would                 -0.328955\n","13          even                 -0.536863\n","14          work                 -0.652401\n","15         money                 -0.901153\n","16         broke                 -1.711417\n","17        return                 -2.066739\n","18         waste                 -2.082077\n","19  disappointed                 -2.318348"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["simple_model_coefficient.head(20)"]},{"cell_type":"markdown","metadata":{},"source":["Are the positive words in the simple_model also positive words in the sentiment_model?"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>simple_model_coefficient</th>\n","      <th>sentimental_model_coefficient</th>\n","    </tr>\n","    <tr>\n","      <th>word</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>loves</th>\n","      <td>1.730101</td>\n","      <td>0.008235</td>\n","    </tr>\n","    <tr>\n","      <th>perfect</th>\n","      <td>1.520583</td>\n","      <td>-0.513307</td>\n","    </tr>\n","    <tr>\n","      <th>love</th>\n","      <td>1.358388</td>\n","      <td>-0.272995</td>\n","    </tr>\n","    <tr>\n","      <th>easy</th>\n","      <td>1.172422</td>\n","      <td>0.008235</td>\n","    </tr>\n","    <tr>\n","      <th>great</th>\n","      <td>0.953138</td>\n","      <td>-0.000006</td>\n","    </tr>\n","    <tr>\n","      <th>well</th>\n","      <td>0.516279</td>\n","      <td>0.000157</td>\n","    </tr>\n","    <tr>\n","      <th>little</th>\n","      <td>0.486670</td>\n","      <td>-0.000056</td>\n","    </tr>\n","    <tr>\n","      <th>able</th>\n","      <td>0.208226</td>\n","      <td>0.358951</td>\n","    </tr>\n","    <tr>\n","      <th>old</th>\n","      <td>0.092202</td>\n","      <td>0.000009</td>\n","    </tr>\n","    <tr>\n","      <th>car</th>\n","      <td>0.062287</td>\n","      <td>0.029050</td>\n","    </tr>\n","    <tr>\n","      <th>less</th>\n","      <td>-0.157199</td>\n","      <td>0.000035</td>\n","    </tr>\n","    <tr>\n","      <th>product</th>\n","      <td>-0.311008</td>\n","      <td>0.009470</td>\n","    </tr>\n","    <tr>\n","      <th>would</th>\n","      <td>-0.328955</td>\n","      <td>0.008235</td>\n","    </tr>\n","    <tr>\n","      <th>even</th>\n","      <td>-0.536863</td>\n","      <td>0.077989</td>\n","    </tr>\n","    <tr>\n","      <th>work</th>\n","      <td>-0.652401</td>\n","      <td>0.019115</td>\n","    </tr>\n","    <tr>\n","      <th>money</th>\n","      <td>-0.901153</td>\n","      <td>-0.235332</td>\n","    </tr>\n","    <tr>\n","      <th>broke</th>\n","      <td>-1.711417</td>\n","      <td>0.000094</td>\n","    </tr>\n","    <tr>\n","      <th>return</th>\n","      <td>-2.066739</td>\n","      <td>0.047759</td>\n","    </tr>\n","    <tr>\n","      <th>waste</th>\n","      <td>-2.082077</td>\n","      <td>-0.000003</td>\n","    </tr>\n","    <tr>\n","      <th>disappointed</th>\n","      <td>-2.318348</td>\n","      <td>-0.031837</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              simple_model_coefficient  sentimental_model_coefficient\n","word                                                                 \n","loves                         1.730101                       0.008235\n","perfect                       1.520583                      -0.513307\n","love                          1.358388                      -0.272995\n","easy                          1.172422                       0.008235\n","great                         0.953138                      -0.000006\n","well                          0.516279                       0.000157\n","little                        0.486670                      -0.000056\n","able                          0.208226                       0.358951\n","old                           0.092202                       0.000009\n","car                           0.062287                       0.029050\n","less                         -0.157199                       0.000035\n","product                      -0.311008                       0.009470\n","would                        -0.328955                       0.008235\n","even                         -0.536863                       0.077989\n","work                         -0.652401                       0.019115\n","money                        -0.901153                      -0.235332\n","broke                        -1.711417                       0.000094\n","return                       -2.066739                       0.047759\n","waste                        -2.082077                      -0.000003\n","disappointed                 -2.318348                      -0.031837"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["simple_model_coefficient = simple_model_coefficient.set_index(\"word\",drop=True)\n","\n","sentiment_model_coefficient = pd.DataFrame({'word':list(vectorizer.vocabulary_),'sentimental_model_coefficient':sentiment_model.coef_.flatten()}).sort_values(['sentimental_model_coefficient'], ascending=False).reset_index(drop=True)\n","sentiment_model_coefficient = sentiment_model_coefficient[sentiment_model_coefficient[\"word\"].isin(significant_words)].set_index(\"word\",drop=True)\n","\n","simple_model_coefficient.join(sentiment_model_coefficient, on=\"word\", how=\"left\")"]},{"cell_type":"markdown","metadata":{},"source":["Which model (sentiment_model or simple_model) has higher accuracy on the TRAINING set?"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentiment Model:  0.97\n","Simple Model:  0.87\n"]}],"source":["print(\"Sentiment Model: \", get_classification_accuracy(sentiment_model, train_matrix, y_train))\n","print(\"Simple Model: \", get_classification_accuracy(simple_model, train_matrix_sub, y_train))"]},{"cell_type":"markdown","metadata":{},"source":["Which model (sentiment_model or simple_model) has higher accuracy on the TEST set?"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sentiment Model:  0.93\n","Simple Model:  0.87\n"]}],"source":["print(\"Sentiment Model: \", get_classification_accuracy(sentiment_model, test_matrix, y_test))\n","print(\"Simple Model: \", get_classification_accuracy(simple_model, test_matrix_sub, y_test))"]},{"cell_type":"markdown","metadata":{},"source":["Find the accuracy of the majority class classifier model on the test_data."]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>col_0</th>\n","      <th>sentiment</th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1</td>\n","      <td>5278</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>28073</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["col_0  sentiment  count\n","0             -1   5278\n","1              1  28073"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# Find Majority Class\n","freq = pd.crosstab(y_test, columns=[\"count\"]).reset_index()\n","freq"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Baseline Model:  0.84\n"]}],"source":["# Majority class=1\n","baseline_model = round(freq[freq[\"sentiment\"]==1][\"count\"].values[0]/freq[\"count\"].sum(), 2)\n","print(\"Baseline Model: \", baseline_model)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.02033068 0.97966932]]\n"]}],"source":["my_review = 'Perfect mobile phone for my wife'\n","predict_review = pd.Series({1: my_review})\n","predict_matrix = vectorizer.transform(predict_review)\n","print(sentiment_model.predict_proba(predict_matrix))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":2}
